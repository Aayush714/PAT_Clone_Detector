{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "def load_big_clone_bench(split=None):\n",
    "    bcb = load_dataset(\"code_x_glue_cc_clone_detection_big_clone_bench\")\n",
    "    if split == None:\n",
    "        return bcb\n",
    "    else:\n",
    "        return bcb[split]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "import javalang.tokenizer as java_tokenizer\n",
    "import pandas as pd\n",
    "from javalang.tree import Literal, MemberReference, ConstructorDeclaration, IfStatement, WhileStatement, ForStatement\n",
    "from javalang.parser import Parser as JavaParser\n",
    "from tqdm import tqdm\n",
    "\n",
    "PARSE_RESULTS = dict()\n",
    "\n",
    "\n",
    "def line_diff(s1: str, s2: str, match_speed=\"real_quick\"):\n",
    "    differ = difflib.Differ()\n",
    "    diff = differ.compare(s1.splitlines(True), s2.splitlines(True))\n",
    "    result = {\"unique_s1_lines\": 0, \"unique_s2_lines\": 0, \"shared_lines\": 0}\n",
    "    for line in diff:\n",
    "        if line.startswith(\"- \"):\n",
    "            result[\"unique_s1_lines\"] += 1\n",
    "        elif line.startswith(\"+ \"):\n",
    "            result[\"unique_s2_lines\"] += 1\n",
    "        elif line.startswith(\"  \"):\n",
    "            result[\"shared_lines\"] += 1\n",
    "    seq_match = difflib.SequenceMatcher(None, s1, s2)\n",
    "    if match_speed == \"slow\":\n",
    "        result[\"similarity_ratio\"] = seq_match.ratio()\n",
    "    elif match_speed == \"quick\":\n",
    "        result[\"similarity_ratio\"] = seq_match.quick_ratio()\n",
    "    elif match_speed == \"real_quick\":\n",
    "        result[\"similarity_ratio\"] = seq_match.real_quick_ratio()\n",
    "    return result\n",
    "\n",
    "\n",
    "def parse_java(java_string):\n",
    "    parse_results = dict()\n",
    "    tokens = java_tokenizer.tokenize(java_string)\n",
    "    parser = JavaParser(tokens)\n",
    "    ast = parser.parse_member_declaration()\n",
    "    nodes = [node for _, node in ast]\n",
    "    parse_results[\"num_literals\"] = 0\n",
    "    parse_results[\"num_if_statements\"] = 0\n",
    "    parse_results[\"num_while_statements\"] = 0\n",
    "    parse_results[\"num_for_statements\"] = 0\n",
    "    unique_identifiers = set()\n",
    "\n",
    "    for node in nodes:\n",
    "        if isinstance(node, Literal):\n",
    "            parse_results[\"num_literals\"] += 1\n",
    "        elif isinstance(node, IfStatement):\n",
    "            parse_results[\"num_if_statements\"] += 1\n",
    "        elif isinstance(node, WhileStatement):\n",
    "            parse_results[\"num_while_statements\"] += 1\n",
    "        elif isinstance(node, ForStatement):\n",
    "            parse_results[\"num_for_statements\"] += 1\n",
    "        elif isinstance(node, MemberReference):\n",
    "            unique_identifiers.add(node.member)\n",
    "\n",
    "    if isinstance(ast, ConstructorDeclaration):\n",
    "        parse_results[\"is_constructor\"] = \"True\"\n",
    "    else:\n",
    "        parse_results[\"is_constructor\"] = \"False\"\n",
    "\n",
    "    if \"parameters\" in ast.attrs:\n",
    "        parse_results[\"num_parameters\"] = len(ast.parameters)\n",
    "    else:\n",
    "        parse_results[\"num_parameters\"] = 0\n",
    "\n",
    "    if \"return_type\" in ast.attrs:\n",
    "        parse_results[\"return_type\"] = ast.return_type\n",
    "    else:\n",
    "        parse_results[\"return_type\"] = None\n",
    "\n",
    "    if \"throws\" in ast.attrs and ast.throws != None:\n",
    "        parse_results[\"num_throws\"] = len(ast.throws)\n",
    "    else:\n",
    "        parse_results[\"num_throws\"] = 0\n",
    "\n",
    "    parse_results[\"num_identifiers\"] = len(unique_identifiers)\n",
    "\n",
    "    return parse_results\n",
    "\n",
    "\n",
    "def get_parse_results(example, func_num):\n",
    "    if example[f\"id{func_num}\"] not in PARSE_RESULTS:\n",
    "        PARSE_RESULTS[example[f\"id{func_num}\"]] = parse_java(\n",
    "            example[f\"func{func_num}\"])\n",
    "    return PARSE_RESULTS[example[f\"id{func_num}\"]]\n",
    "\n",
    "\n",
    "def combine_parse_results(s1_parse_results, s2_parse_results):\n",
    "    shared_results = dict()\n",
    "    for key in s1_parse_results:\n",
    "        if isinstance(s1_parse_results[key], int):\n",
    "            shared_results[f\"{key}_s1\"] = s1_parse_results[key]\n",
    "            shared_results[f\"{key}_s2\"] = s2_parse_results[key]\n",
    "        elif s1_parse_results[key] == s2_parse_results[key]:\n",
    "            shared_results[f\"same_{key}\"] = 1\n",
    "        else:\n",
    "            shared_results[f\"same_{key}\"] = 0\n",
    "    return shared_results\n",
    "\n",
    "\n",
    "def merge_dicts(*dict_args):\n",
    "    result = dict()\n",
    "    for dictionary in dict_args:\n",
    "        result.update(dictionary)\n",
    "    return result\n",
    "\n",
    "\n",
    "def big_clone_bench_preprocess(bcb, csv_filename=None):\n",
    "    '''\n",
    "    Generates DataFrame of features from an input in the format of the BigCloneBench dataset https://huggingface.co/datasets/code_x_glue_cc_clone_detection_big_clone_bench\n",
    "    '''\n",
    "    df = pd.DataFrame()\n",
    "    print(f\"Preprocessing {len(bcb)} examples...\")\n",
    "    for i in tqdm(range(len(bcb))):\n",
    "        example = bcb[i]\n",
    "        example_dict = line_diff(example[\"func1\"], example[\"func2\"])\n",
    "        func1_parse_results = get_parse_results(example, 1)\n",
    "        func2_parse_results = get_parse_results(example, 2)\n",
    "        shared_results = combine_parse_results(\n",
    "            func1_parse_results, func2_parse_results)\n",
    "        example_dict = merge_dicts(example_dict, shared_results)\n",
    "        example_dict[\"target\"] = int(example[\"label\"])\n",
    "        df = pd.concat([df, pd.DataFrame([example_dict])], ignore_index=True)\n",
    "    if csv_filename != None:\n",
    "        df.to_csv(csv_filename)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage: ipykernel_launcher.py [OPTIONS]\n",
      "Try 'ipykernel_launcher.py --help' for help.\n",
      "\n",
      "Error: No such option: --ip Did you mean --help?\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchOption\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/click/core.py:1054\u001b[0m, in \u001b[0;36mBaseCommand.main\u001b[0;34m(self, args, prog_name, complete_var, standalone_mode, windows_expand_args, **extra)\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1054\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmake_context(prog_name, args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra) \u001b[39mas\u001b[39;00m ctx:\n\u001b[1;32m   1055\u001b[0m         rv \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minvoke(ctx)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/click/core.py:920\u001b[0m, in \u001b[0;36mBaseCommand.make_context\u001b[0;34m(self, info_name, args, parent, **extra)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[39mwith\u001b[39;00m ctx\u001b[39m.\u001b[39mscope(cleanup\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 920\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse_args(ctx, args)\n\u001b[1;32m    921\u001b[0m \u001b[39mreturn\u001b[39;00m ctx\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/click/core.py:1375\u001b[0m, in \u001b[0;36mCommand.parse_args\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m   1374\u001b[0m parser \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_parser(ctx)\n\u001b[0;32m-> 1375\u001b[0m opts, args, param_order \u001b[39m=\u001b[39m parser\u001b[39m.\u001b[39;49mparse_args(args\u001b[39m=\u001b[39;49margs)\n\u001b[1;32m   1377\u001b[0m \u001b[39mfor\u001b[39;00m param \u001b[39min\u001b[39;00m iter_params_for_processing(param_order, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params(ctx)):\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/click/parser.py:337\u001b[0m, in \u001b[0;36mOptionParser.parse_args\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 337\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_args_for_options(state)\n\u001b[1;32m    338\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_args_for_args(state)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/click/parser.py:364\u001b[0m, in \u001b[0;36mOptionParser._process_args_for_options\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[39melif\u001b[39;00m arg[:\u001b[39m1\u001b[39m] \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_opt_prefixes \u001b[39mand\u001b[39;00m arglen \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_opts(arg, state)\n\u001b[1;32m    365\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mallow_interspersed_args:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/click/parser.py:514\u001b[0m, in \u001b[0;36mOptionParser._process_opts\u001b[0;34m(self, arg, state)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 514\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_match_long_opt(norm_long_opt, explicit_value, state)\n\u001b[1;32m    515\u001b[0m \u001b[39mexcept\u001b[39;00m NoSuchOption:\n\u001b[1;32m    516\u001b[0m     \u001b[39m# At this point the long option matching failed, and we need\u001b[39;00m\n\u001b[1;32m    517\u001b[0m     \u001b[39m# to try with short options.  However there is a special rule\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[39m# short option code and will instead raise the no option\u001b[39;00m\n\u001b[1;32m    521\u001b[0m     \u001b[39m# error.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/click/parser.py:398\u001b[0m, in \u001b[0;36mOptionParser._match_long_opt\u001b[0;34m(self, opt, explicit_value, state)\u001b[0m\n\u001b[1;32m    397\u001b[0m     possibilities \u001b[39m=\u001b[39m get_close_matches(opt, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_long_opt)\n\u001b[0;32m--> 398\u001b[0m     \u001b[39mraise\u001b[39;00m NoSuchOption(opt, possibilities\u001b[39m=\u001b[39mpossibilities, ctx\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mctx)\n\u001b[1;32m    400\u001b[0m option \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_long_opt[opt]\n",
      "\u001b[0;31mNoSuchOption\u001b[0m: No such option: --ip",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m/Users/aayushgupta/Library/Mobile Documents/com~apple~CloudDocs/Program testing and analysis/PAT-Clone-Detection/Parameters.ipynb Cell 3\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aayushgupta/Library/Mobile%20Documents/com~apple~CloudDocs/Program%20testing%20and%20analysis/PAT-Clone-Detection/Parameters.ipynb#W1sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/aayushgupta/Library/Mobile%20Documents/com~apple~CloudDocs/Program%20testing%20and%20analysis/PAT-Clone-Detection/Parameters.ipynb#W1sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m     main()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/click/core.py:1130\u001b[0m, in \u001b[0;36mBaseCommand.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[39m\"\"\"Alias for :meth:`main`.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1130\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmain(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/click/core.py:1073\u001b[0m, in \u001b[0;36mBaseCommand.main\u001b[0;34m(self, args, prog_name, complete_var, standalone_mode, windows_expand_args, **extra)\u001b[0m\n\u001b[1;32m   1072\u001b[0m     e\u001b[39m.\u001b[39mshow()\n\u001b[0;32m-> 1073\u001b[0m     sys\u001b[39m.\u001b[39;49mexit(e\u001b[39m.\u001b[39;49mexit_code)\n\u001b[1;32m   1074\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mSystemExit\u001b[0m: 2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py:1987\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   1984\u001b[0m \u001b[39mif\u001b[39;00m exception_only:\n\u001b[1;32m   1985\u001b[0m     stb \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mAn exception has occurred, use \u001b[39m\u001b[39m%\u001b[39m\u001b[39mtb to see \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1986\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mthe full traceback.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m]\n\u001b[0;32m-> 1987\u001b[0m     stb\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mInteractiveTB\u001b[39m.\u001b[39;49mget_exception_only(etype,\n\u001b[1;32m   1988\u001b[0m                                                      value))\n\u001b[1;32m   1989\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1990\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1991\u001b[0m         \u001b[39m# Exception classes can customise their traceback - we\u001b[39;00m\n\u001b[1;32m   1992\u001b[0m         \u001b[39m# use this in IPython.parallel for exceptions occurring\u001b[39;00m\n\u001b[1;32m   1993\u001b[0m         \u001b[39m# in the engines. This should return a list of strings.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/IPython/core/ultratb.py:579\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_exception_only\u001b[39m(\u001b[39mself\u001b[39m, etype, value):\n\u001b[1;32m    572\u001b[0m     \u001b[39m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \n\u001b[1;32m    574\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[39m    value : exception value\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 579\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39;49mstructured_traceback(\u001b[39mself\u001b[39;49m, etype, value)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/IPython/core/ultratb.py:446\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    443\u001b[0m     chained_exc_ids\u001b[39m.\u001b[39madd(\u001b[39mid\u001b[39m(exception[\u001b[39m1\u001b[39m]))\n\u001b[1;32m    444\u001b[0m     chained_exceptions_tb_offset \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    445\u001b[0m     out_list \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 446\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[1;32m    447\u001b[0m             etype, evalue, (etb, chained_exc_ids),\n\u001b[1;32m    448\u001b[0m             chained_exceptions_tb_offset, context)\n\u001b[1;32m    449\u001b[0m         \u001b[39m+\u001b[39m chained_exception_message\n\u001b[1;32m    450\u001b[0m         \u001b[39m+\u001b[39m out_list)\n\u001b[1;32m    452\u001b[0m \u001b[39mreturn\u001b[39;00m out_list\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/IPython/core/ultratb.py:1112\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1111\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtb \u001b[39m=\u001b[39m tb\n\u001b[0;32m-> 1112\u001b[0m \u001b[39mreturn\u001b[39;00m FormattedTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[1;32m   1113\u001b[0m     \u001b[39mself\u001b[39;49m, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/IPython/core/ultratb.py:1006\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1003\u001b[0m mode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode\n\u001b[1;32m   1004\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose_modes:\n\u001b[1;32m   1005\u001b[0m     \u001b[39m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[0;32m-> 1006\u001b[0m     \u001b[39mreturn\u001b[39;00m VerboseTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[1;32m   1007\u001b[0m         \u001b[39mself\u001b[39;49m, etype, value, tb, tb_offset, number_of_lines_of_context\n\u001b[1;32m   1008\u001b[0m     )\n\u001b[1;32m   1009\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mMinimal\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m   1010\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39mget_exception_only(\u001b[39mself\u001b[39m, etype, value)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/IPython/core/ultratb.py:859\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstructured_traceback\u001b[39m(\n\u001b[1;32m    851\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    852\u001b[0m     etype: \u001b[39mtype\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    856\u001b[0m     number_of_lines_of_context: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m,\n\u001b[1;32m    857\u001b[0m ):\n\u001b[1;32m    858\u001b[0m     \u001b[39m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m     formatted_exception \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[1;32m    860\u001b[0m                                                            tb_offset)\n\u001b[1;32m    862\u001b[0m     colors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mColors  \u001b[39m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[1;32m    863\u001b[0m     colorsnormal \u001b[39m=\u001b[39m colors\u001b[39m.\u001b[39mNormal  \u001b[39m# used a lot\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/IPython/core/ultratb.py:793\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(tb_offset, \u001b[39mint\u001b[39m)\n\u001b[1;32m    791\u001b[0m head \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_header(etype, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlong_header)\n\u001b[1;32m    792\u001b[0m records \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 793\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_records(etb, number_of_lines_of_context, tb_offset) \u001b[39mif\u001b[39;00m etb \u001b[39melse\u001b[39;00m []\n\u001b[1;32m    794\u001b[0m )\n\u001b[1;32m    796\u001b[0m frames \u001b[39m=\u001b[39m []\n\u001b[1;32m    797\u001b[0m skipped \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/IPython/core/ultratb.py:848\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m    842\u001b[0m     formatter \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    843\u001b[0m options \u001b[39m=\u001b[39m stack_data\u001b[39m.\u001b[39mOptions(\n\u001b[1;32m    844\u001b[0m     before\u001b[39m=\u001b[39mbefore,\n\u001b[1;32m    845\u001b[0m     after\u001b[39m=\u001b[39mafter,\n\u001b[1;32m    846\u001b[0m     pygments_formatter\u001b[39m=\u001b[39mformatter,\n\u001b[1;32m    847\u001b[0m )\n\u001b[0;32m--> 848\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(stack_data\u001b[39m.\u001b[39;49mFrameInfo\u001b[39m.\u001b[39;49mstack_data(etb, options\u001b[39m=\u001b[39;49moptions))[tb_offset:]\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/stack_data/core.py:578\u001b[0m, in \u001b[0;36mFrameInfo.stack_data\u001b[0;34m(cls, frame_or_tb, options, collapse_repeated_frames)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    563\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstack_data\u001b[39m(\n\u001b[1;32m    564\u001b[0m         \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    568\u001b[0m         collapse_repeated_frames: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    569\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Union[\u001b[39m'\u001b[39m\u001b[39mFrameInfo\u001b[39m\u001b[39m'\u001b[39m, RepeatedFrames]]:\n\u001b[1;32m    570\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[39m    An iterator of FrameInfo and RepeatedFrames objects representing\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[39m    a full traceback or stack. Similar consecutive frames are collapsed into RepeatedFrames\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[39m    and optionally an Options object to configure.\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 578\u001b[0m     stack \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(iter_stack(frame_or_tb))\n\u001b[1;32m    580\u001b[0m     \u001b[39m# Reverse the stack from a frame so that it's in the same order\u001b[39;00m\n\u001b[1;32m    581\u001b[0m     \u001b[39m# as the order from a traceback, which is the order of a printed\u001b[39;00m\n\u001b[1;32m    582\u001b[0m     \u001b[39m# traceback when read top to bottom (most recent call last)\u001b[39;00m\n\u001b[1;32m    583\u001b[0m     \u001b[39mif\u001b[39;00m is_frame(frame_or_tb):\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/stack_data/utils.py:98\u001b[0m, in \u001b[0;36miter_stack\u001b[0;34m(frame_or_tb)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39mwhile\u001b[39;00m frame_or_tb:\n\u001b[1;32m     97\u001b[0m     \u001b[39myield\u001b[39;00m frame_or_tb\n\u001b[0;32m---> 98\u001b[0m     \u001b[39mif\u001b[39;00m is_frame(frame_or_tb):\n\u001b[1;32m     99\u001b[0m         frame_or_tb \u001b[39m=\u001b[39m frame_or_tb\u001b[39m.\u001b[39mf_back\n\u001b[1;32m    100\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/stack_data/utils.py:91\u001b[0m, in \u001b[0;36mis_frame\u001b[0;34m(frame_or_tb)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_frame\u001b[39m(frame_or_tb: Union[FrameType, TracebackType]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[0;32m---> 91\u001b[0m     assert_(\u001b[39misinstance\u001b[39;49m(frame_or_tb, (types\u001b[39m.\u001b[39;49mFrameType, types\u001b[39m.\u001b[39;49mTracebackType)))\n\u001b[1;32m     92\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39misinstance\u001b[39m(frame_or_tb, (types\u001b[39m.\u001b[39mFrameType,))\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/stack_data/utils.py:172\u001b[0m, in \u001b[0;36massert_\u001b[0;34m(condition, error)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(error, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    171\u001b[0m     error \u001b[39m=\u001b[39m \u001b[39mAssertionError\u001b[39;00m(error)\n\u001b[0;32m--> 172\u001b[0m \u001b[39mraise\u001b[39;00m error\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from data_loader import load_big_clone_bench\n",
    "from data_preprocess import big_clone_bench_preprocess\n",
    "\n",
    "import click\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from joblib import load\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def load_model(classifier):\n",
    "    if classifier == 'svm':\n",
    "        # Get the SVM model\n",
    "        trained_model = load('svm.pkl')\n",
    "        pass\n",
    "    elif classifier == 'random_forest':\n",
    "        # get the Random Forest model\n",
    "        trained_model = load('random_forest.joblib')\n",
    "        pass\n",
    "    return trained_model\n",
    "\n",
    "\n",
    "def obtain_features(data_df):\n",
    "    features = data_df.drop(\"target\", axis=1)\n",
    "\n",
    "    # TODO: Remove this when models are trained on new features\n",
    "    if (len(features.columns) > 4):\n",
    "        features = features[['unique_s1_lines',\n",
    "                             'unique_s2_lines', 'shared_lines', 'similarity_ratio']]\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def evaluate_clone_detection(classifier, val_output, test_output):\n",
    "    \"\"\"\n",
    "    evaluate the clone detection model on the given validation, and test datasets.\n",
    "    \"\"\"\n",
    "    # Load validation datasets\n",
    "    val_bcb = load_big_clone_bench(\"validation\")\n",
    "    val_df = big_clone_bench_preprocess(val_bcb)\n",
    "\n",
    "    # load test dataset\n",
    "    test_bcb = load_big_clone_bench(\"test\")\n",
    "    test_df = big_clone_bench_preprocess(test_bcb)\n",
    "\n",
    "    # load the trained model\n",
    "    trained_model = load_model(classifier)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    val_predictions = trained_model.predict(obtain_features(val_df))\n",
    "    # Save val predictions to a CSV file\n",
    "    pd.DataFrame({\"validation_prediction\": val_predictions}\n",
    "                 ).to_csv(val_output, index=False)\n",
    "\n",
    "    # get the validation accuracy\n",
    "    val_accuracy = accuracy_score(val_df[\"target\"], val_predictions)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_predictions = trained_model.predict(obtain_features(test_df))\n",
    "    # Save test predictions to a CSV file\n",
    "    pd.DataFrame({\"test_prediction\": val_predictions}\n",
    "                 ).to_csv(test_output, index=False)\n",
    "\n",
    "    # get the test accuracy\n",
    "    test_accuracy = accuracy_score(test_df[\"target\"], test_predictions)\n",
    "\n",
    "    # Print results\n",
    "    click.echo(f'Validation accuracy: {val_accuracy}')\n",
    "    click.echo(f'Test accuracy: {test_accuracy}')\n",
    "\n",
    "\n",
    "def predict_custom_data(custom_data, classifier, prediction_output):\n",
    "    bcb_format_data = pd.read_csv(\n",
    "        custom_data, names=[\"id\", \"id1\", \"id2\", \"func1\", \"func2\", \"label\"])\n",
    "    data_dicts = bcb_format_data.to_dict('records')\n",
    "    data_df = big_clone_bench_preprocess(data_dicts)\n",
    "\n",
    "    trained_model = load_model(classifier)\n",
    "\n",
    "    predictions = trained_model.predict(obtain_features(data_df))\n",
    "    pd.DataFrame({\"prediction\": predictions}).to_csv(\n",
    "        prediction_output, index=False)\n",
    "    click.echo(f'Predictions saved to {prediction_output}')\n",
    "\n",
    "\n",
    "@click.command()\n",
    "@click.option('--custom_data', type=click.Path(), default=\"\", help=\"csv file containing snippets in the same schema as https://huggingface.co/datasets/code_x_glue_cc_clone_detection_big_clone_bench\")\n",
    "@click.option('--prediction_output', type=click.Path(), default=\"prediction.csv\", help=\"Path to save custom dataset prediction\")\n",
    "@click.option('--classifier', type=click.Choice(['svm', 'random_forest']), default='random_forest', help='Set the trained model')\n",
    "@click.option('--val_output', type=click.Path(), default='val_prediction.csv', help=\"Path to save the val prediction\")\n",
    "@click.option('--test_output', type=click.Path(), default='test_prediction.csv', help=\"Path to save the test prediction\")\n",
    "def main(custom_data, prediction_output, classifier, val_output, test_output):\n",
    "    if custom_data == \"\":\n",
    "        evaluate_clone_detection(classifier, val_output, test_output)\n",
    "    else:\n",
    "        predict_custom_data(custom_data, classifier, prediction_output)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
